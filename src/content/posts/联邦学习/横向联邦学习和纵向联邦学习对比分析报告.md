---
title: 这是我的第一篇正式文章
published: 2026-01-10
description: 这是我第一篇文章用来测试使用改功能
image: "./cover.jpg" # 文章封面图（可选）
tags: [测试, 测试]
category: 日志
draft: false # 如果设为 true，文章将不会发布
---
# 横向联邦学习与纵向联邦学习的异同分析
横向联邦学习（Horizontal Federated Learning, HFL）与纵向联邦学习（Vertical Federated Learning, VFL）是联邦学习的两大核心范式，二者均以“数据不出本地、模型协同训练”为核心目标，但在**数据划分逻辑、参与方协作模式、适用场景**等方面存在本质差异。以下从「核心定义、异同对比、实践落地差异」三方面展开深度解析，结合金融表格处理等场景强化理解：

## 一、核心定义先明确
### 1. 横向联邦学习（HFL）
- **本质**：「样本级联邦」—— 参与方拥有**相同特征空间（列相同）、不同样本集合（行不同）**，即“数据横向分割”。
  例：A银行和B银行都处理企业财务报表（特征均为“流动比率、毛利率、负债总额”等表格字段），但服务不同企业客户（样本不同），通过HFL联合训练，共享模型参数而非原始客户数据。
- **形象比喻**：多个超市（参与方）卖相同类型的商品（特征），但服务不同区域的顾客（样本），联合优化“商品推荐模型”。

### 2. 纵向联邦学习（VFL）
- **本质**：「特征级联邦」—— 参与方拥有**相同样本集合（行相同）、不同特征空间（列不同）**，即“数据纵向分割”。
  例：银行（拥有企业“账户流水、贷款记录”特征）与税务部门（拥有企业“纳税金额、报税记录”特征），针对同一批企业（样本相同）联合训练风控模型，双方特征互补但不泄露原始数据。
- **形象比喻**：同一批顾客（样本）在不同商家（参与方）购买不同类型的商品（特征），联合分析“顾客消费能力模型”。

## 二、核心异同对比（表格清晰呈现）
| 对比维度                | 横向联邦学习（HFL）                                  | 纵向联邦学习（VFL）                                  | 共同特征                                              |
|-------------------------|-------------------------------------------------------|-------------------------------------------------------|-------------------------------------------------------|
| **数据划分逻辑**        | 样本分割（行拆分）：特征重叠多，样本重叠少            | 特征分割（列拆分）：样本重叠多，特征重叠少            | 1. 数据均不出本地，保护原始数据隐私；<br>2. 分布式训练+全局聚合，解决数据孤岛；<br>3. 需通过加密技术（如HE、DP）保障传输安全；<br>4. 均面临非IID数据、通信效率、合规性挑战。 |
| **参与方数据特征**      | 各参与方数据格式一致（如均为“财务报表表格”，字段完全相同） | 各参与方数据格式互补（如一方是“表格视觉特征”，一方是“表格文本语义特征”） |                                                       |
| **样本ID对齐需求**      | 低：无需强制对齐样本ID（因样本无重叠）                | 高：必须通过隐私集合交集（PSI）技术对齐样本ID（仅保留双方共有的样本，不泄露非共有样本） |                                                       |
| **通信内容**            | 本地模型的梯度、参数更新或中间特征向量（数据量较大）  | 加密后的特征映射、模型中间输出或梯度（数据量较小，但加密复杂度高） |                                                       |
| **隐私保护重点**        | 防止样本信息泄露（如某银行的客户具体财务数据）        | 防止特征信息泄露（如税务部门的企业纳税细节、银行的贷款额度） |                                                       |
| **适用场景**            | 跨机构同类数据协作（样本异构，特征同构）：<br>- 跨银行财务报表风控；<br>- 多律所合同表格结构识别；<br>- 跨医院同款检验报告解析 | 跨机构互补数据协作（特征异构，样本同构）：<br>- 银行+税务的企业信用评估；<br>- 跨境支付中“汇款方信息+收款方信息”联合反洗钱；<br>- 表格识别中“视觉特征（边缘端）+文本语义（云端）”融合 |                                                       |
| **技术核心挑战**        | 1. 非IID数据（样本分布不均，如A银行优质客户多、B银行风险客户多）；<br>2. 通信开销大（大量参数/梯度传输）；<br>3. 节点异构（不同机构硬件算力差异） | 1. 特征对齐与异构特征融合（如表格视觉特征与文本特征的语义匹配）；<br>2. 梯度泄露风险（攻击者通过加密梯度反推原始特征）；<br>3. 样本对齐的隐私安全（PSI技术需防信息泄露） |                                                       |
| **典型优化算法**        | FedAvg（基础）、FedProx（缓解非IID）、MOON（对比学习增强）、梯度稀疏化（通信优化） | SecureBoost（树模型）、FedV（特征融合）、分层加密（HE+DP结合）、PSI优化（如基于OT的高效对齐） |                                                       |
| **模型训练效率**        | 通信效率低（参数量大），训练周期较长；但加密复杂度低  | 通信效率高（数据量小），训练周期较短；但加密复杂度高（需处理异构特征的密态计算） |                                                       |

## 三、关键差异的实践落地体现（结合金融表格场景）
### 1. 数据预处理阶段
- **HFL场景**：跨3家银行训练“财务报表违约预测模型”，3家银行的报表字段完全一致（如资产负债表核心指标），仅客户样本不同。预处理无需对齐ID，仅需统一数据格式（如表格字段归一化、缺失值填充），直接本地提取特征后上传梯度。
- **VFL场景**：银行（拥有“报表表格的金额特征”）与会计师事务所（拥有“报表审计意见特征”）联合建模，需先通过PSI技术对齐“同一企业”样本（仅确认双方共有的企业ID，不泄露各自独有的企业信息），再分别提取异构特征进行加密融合。

### 2. 隐私保护策略
- **HFL**：因传输的是模型参数/梯度，多采用「差分隐私（DP）+梯度稀疏化」—— 对梯度注入少量噪声，同时仅传输关键梯度（如前20%重要梯度），平衡隐私与模型精度。例如跨银行HFL模型中，DP的ε值设为0.8，模型准确率仅下降2%。
- **VFL**：因传输的是异构特征，多采用「同态加密（HE）+隐私集合交集（PSI）」—— 特征映射后用HE加密传输，PSI对齐样本时采用“不经意传输（OT）”技术，防止第三方窃取样本ID或特征信息。例如跨境支付VFL中，银行与清算机构通过HE加密传输“交易金额特征”与“SWIFT代码特征”，密态下完成模型训练。

### 3. 模型效果影响因素
- **HFL**：性能瓶颈在于「非IID数据」—— 若某银行的表格数据中“合并单元格表格”占比90%，而其他银行仅占10%，会导致全局模型偏向该银行的数据分布，需通过FedProx引入近端项约束参数更新方向，缓解偏差。
- **VFL**：性能瓶颈在于「特征融合质量」—— 银行的“数值特征”与税务部门的“文本特征”（如审计意见“无保留/保留”）需先映射到同一语义空间，再通过注意力机制加权融合，否则会出现“特征异构导致的模型偏差”。例如某VFL模型通过LayoutLMv3将表格文本特征与数值特征对齐，结构识别F1值提升8%。

## 四、总结：核心差异一句话概括
- **横向联邦学习**：「多用户、同特征」—— 解决“同类数据分散在不同机构，样本不足”的问题，核心是“参数共享+非IID优化”；
- **纵向联邦学习**：「同用户、多特征」—— 解决“同一批样本的特征分散在不同机构，信息不全”的问题，核心是“特征融合+隐私对齐”。

两者的选择完全依赖**数据分布特点**：若参与方数据“长得一样（特征同）、服务对象不同（样本异）”，选HFL；若参与方“服务同一批对象（样本同）、数据维度不同（特征异）”，选VFL。在金融表格处理中，HFL更适合跨机构同类表格的批量识别与分析，VFL更适合跨部门互补信息的深度建模（如风控、反洗钱）。
